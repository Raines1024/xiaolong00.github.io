---
layout: post
title: Spark环境搭建及helloCount
description: centos下spark环境搭建；spark入门
category: blog
date: 2020-01-07 13:50:39
---

## 环境

### centos
#### 查看centos版本   
rpm -q centos-release  
#### 更换centos默认镜像库   
163链接[http://mirrors.163.com/.help/centos.html]  
1. 首先备份/etc/yum.repos.d/CentOS-Base.repo  

    
    mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup

2. 下载对应版本repo文件, 放入/etc/yum.repos.d/(操作前请做好相应备份)
3.  运行以下命令生成缓存  

    
    yum clean all
    yum makecache


### linux CentOS 安装rz和sz命令 lrzsz
- lrzsz在linux里可代替ftp上传和下载。  
- lrzsz是一个unix通信套件提供的X，Y，和ZModem文件传输协议  
#### yum安装
yum -y install lrzsz   
#### 基本操作
上传文件，执行命令rz，会跳出文件选择窗口，选择好文件，点击确认即可。
    
    rz
下载文件，执行命令sz

    sz 文件名

### Spark环境搭建

#### JDK
1. 卸掉默认的jdk版本  
得到目前jdk的版本  
rpm -qa|grep jdk  
删除  
yum -y remove java java-1.7.0-openjdk-headless-1.7.0.51-2.4.5.5.el7.x86_64  
2. 下载jdk包  
tar -xvzf jdk-8u121-linux-x64.tar.gz  
解压好之后，创建个软连接，方便以后更改版本  
ln -sf /spark/jdk1.8.0_121/ /usr/local/jdk  

- ln -sf用法  
b--->a  
ln -sf a b  
b指向a  

#### scala  
ln -sf /spark/scala-2.10.4/ /usr/local/scala   

#### spark  
ln -sf /spark/spark-1.6.3-bin-hadoop2.6/ /usr/local/spark-bin-hadoop  

#### 添加到全局变量
1. vi /etc/profile  
2.添加路径到文件：  
export JAVA_HOME=/usr/local/jdk  
export SCALA_HOME=/usr/local/scala  
export SPARK_HOME=/usr/local/spark-bin-hadoop    
export PATH=.:${JAVA_HOME}/bin:${SCALA_HOME}/bin:${SPARK_HOME}/bin:$PATH  
3. 即时生效
source /etc/profile  
4. 查看版本号  
java -version  
scala -version  

#### yum安装maven
yum install maven  
1. 查看maven版本，并查询maven地址，修改一下maven的中央仓库镜像地址（spark下载速度，你懂得）  
mvn -version
2. 修改mirrors节点，添加阿里云的镜像地址

```
<mirror>
  <id>alimaven</id>
  <name>aliyun maven</name>
  <url>http://maven.aliyun.com/nexus/content/groups/public/</url>
  <mirrorOf>central</mirrorOf>
</mirror>
```

保存一下。

## 启动spark服务
1. 回到spark安装根目录，进入conf文件夹，修改配置文件  
cp spark-env.sh.template spark-env.sh  
vi spark-env.sh.template  
再开头添加环境  
export JAVA_HOME=/usr/local/jdk  
export SCALA_HOME=/usr/local/scala  
2. 回到spark根目录  
sbin/start-master.sh 
3. 在主机网页输入地址http://yourip:8080/ 访问,如果访问不到，说明虚拟机的防火墙打开了，这里要关掉  
service firewalld stop   
4. 启动worker  
bin/spark-class org.apache.spark.deploy.worker.Worker spark://localhost.localdomain:7077  


【错误解决方案】  

    Failed to connect to master localhost.localdomain:

添加master启动参数，修改了Master的启动方法
./sbin/start-master.sh -h master_ip  
成功启动后，可以通过http://master_ip:8080/连接到Master的UI，并在页面中找到URL为spark://master_ip:7077。注意这里的URL已经由spark://host_name:7077变为spark://master_ip:7077。  
然后，通过如下命令，成功启动了Slave！  
./sbin/start-slave.sh spark://master_ip:7077  
用-h参数启动Master，连接到Master的UI，确保URL是spark://master_ip:7077，而非spark://host_name:7077。这样Slave连接Master的问题不会再出现。  

## 提交任务给spark
进入spa安装根目录  
1. 新建opt/目录，存放要解析的文本  
2. 运行命令，成功的话统计结果会输出在屏幕上
bin/spark-submit --master spark://yourip:7077 --class WorldCount /spark/sparkDemo/target/spark.jar-1.0-SNAPSHOT.jar

## 总结
说实话，想一个spark与java程序彻底打通一直觉得没啥费事的，真是年少气盛，说起来容易做起来难的事情太多。  
- 环境部署的要正确，版本号要统一  
- spark启动的顺序  
sbin/start-master.sh # 启动服务  
bin/spark-class org.apache.spark.deploy.worker.Worker spark://localhost.localdomain:7077 # 启动worker  
bin/spark-submit --master spark://localhost.localdomain:7077 --class WorldCount /usr/local/code/target/spark.jar-1.0-SNAPSHOT.jar # 提交任务  
- 碰到错误的步骤  
查看是否是之前操作有误  
查看是否是历史环境或操作有误  
查看是否是配置文件有误  
多维思考问题，报错的信息可能不是错误的根本原因  
尝试修改错误时一定要记得自己做的操作，成功则知道自己做的啥成功，失败则可以回退。  

## 感谢
感谢冬天只爱早晨的省路[https://www.jianshu.com/p/52d0f043cc04?from=singlemessage]  
感谢谢东演唱的笑脸，陪伴我成功打通第一个java与spark程序。  
不知不觉中跟唱：书上说有情人千里能共婵娟，可是我现在只想把你手儿牵，听说过许多山盟海誓的表演，突然想看看你曾经纯真的笑脸。  

## 修改hosts文件
/etc/hosts  
/etc/sysconfig/network  
- 配置完执行刷新 systemctl restart network  
- 验证  
hostname     
hostname -i  
 

































